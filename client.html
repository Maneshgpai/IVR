<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WhatsApp-like Audio Chat</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #e5ddd5;
        }
        .chat-container {
            max-width: 600px;
            margin: 20px auto;
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 1px 1px 0 rgba(0,0,0,.06),0 2px 5px 0 rgba(0,0,0,.2);
        }
        .chat-header {
            background-color: #075e54;
            color: #fff;
            padding: 10px;
            border-top-left-radius: 10px;
            border-top-right-radius: 10px;
        }
        .chat-messages {
            height: 400px;
            overflow-y: auto;
            padding: 10px;
        }
        .message {
            max-width: 80%;
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 7.5px;
            position: relative;
            display: inline-block;
        }
        .user-message {
            background-color: #dcf8c6;
            float: right;
            clear: both;
        }
        .bot-message {
            background-color: #fff;
            float: left;
            clear: both;
        }
        .timestamp {
            font-size: 0.75em;
            color: #999;
            margin-top: 5px;
        }
        .chat-input {
            display: flex;
            align-items: center;
            padding: 10px;
            background-color: #f0f0f0;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
        }
        .record-button {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            border: none;
            background-color: #128c7e;
            color: white;
            font-size: 24px;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .record-button.recording {
            background-color: #ff0000;
        }
        .status {
            margin-left: 10px;
            color: #555;
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="chat-header">
            <h2>Real time talk with A.I </h2>
        </div>
        <div id="chatMessages" class="chat-messages"></div>
        <div class="chat-input">
            <button id="recordButton" class="record-button">ðŸ“ž</button>
            <div id="status" class="status"></div>
        </div>
    </div>

    <script>
        let ws;
        let audioContext;
        let mediaStreamSource;
        let processor;
        let isRecording = false;
        let audioQueue = [];
        let isPlaying = false;

        const recordButton = document.getElementById('recordButton');
        const statusDiv = document.getElementById('status');
        const chatMessages = document.getElementById('chatMessages');

        recordButton.onclick = toggleRecording;

        function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        function startRecording() {
            ws = new WebSocket('ws://localhost:8080');
            audioQueue = [];
            isPlaying = false;
            
            ws.onopen = () => {
                console.log('WebSocket connected');
                statusDiv.textContent = 'Connected. Speak now...';
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                        mediaStreamSource = audioContext.createMediaStreamSource(stream);
                        processor = audioContext.createScriptProcessor(4096, 1, 1);

                        mediaStreamSource.connect(processor);
                        processor.connect(audioContext.destination);

                        processor.onaudioprocess = (e) => {
                            if (isRecording && ws.readyState === WebSocket.OPEN) {
                                const inputData = e.inputBuffer.getChannelData(0);
                                const pcm16 = convertToPCM16(inputData);
                                ws.send(pcm16);
                            }
                        };

                        isRecording = true;
                        recordButton.classList.add('recording');
                    });
            };

            ws.onmessage = (event) => {
                const response = JSON.parse(event.data);
                console.log('Received message:', response.type);
                if (response.type === 'audio_delta') {
                    console.log('Received audio delta');
                    const audioData = base64ToArrayBuffer(response.data);
                    audioQueue.push(audioData);
                    if (!isPlaying) {
                        playNextAudioChunk();
                    }
                } else if (response.type === 'user_transcript') {
                    addMessage('You', response.transcript, 'user-message');
                } else if (response.type === 'bot_transcript') {
                    addMessage('Assistant', response.transcript, 'bot-message');
                } else if (response.type === 'audio_end') {
                    console.log('Received audio end signal');
                    statusDiv.textContent = 'Response complete.';
                } else if (response.type === 'error') {
                    console.error('Error:', response.message);
                    statusDiv.textContent = 'Error: ' + response.message;
                }
            };

            ws.onerror = (error) => {
                console.error('WebSocket Error:', error);
                statusDiv.textContent = 'Connection error.';
            };

            ws.onclose = () => {
                console.log('WebSocket disconnected');
                statusDiv.textContent = 'Disconnected.';
            };
        }

        function stopRecording() {
            console.log('Stopping recording');
            isRecording = false;
            if (processor) {
                processor.disconnect();
                mediaStreamSource.disconnect();
            }
            if (audioContext) {
                audioContext.close();
            }
            ws.send('END_OF_AUDIO');
            recordButton.classList.remove('recording');
            statusDiv.textContent = 'Processing...';
        }

        function convertToPCM16(float32Array) {
            const pcm16 = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return pcm16.buffer;
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function playNextAudioChunk() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            isPlaying = true;
            const audioData = audioQueue.shift();
            const audioBuffer = audioContext.createBuffer(1, audioData.byteLength / 2, audioContext.sampleRate);
            const channelData = audioBuffer.getChannelData(0);
            const int16Array = new Int16Array(audioData);

            for (let i = 0; i < int16Array.length; i++) {
                channelData[i] = int16Array[i] / 32768;
            }

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.onended = playNextAudioChunk;
            source.start();

            statusDiv.textContent = 'Playing response...';
        }

        function addMessage(sender, message, className) {
            const messageElement = document.createElement('div');
            messageElement.className = `message ${className}`;
            
            const contentElement = document.createElement('div');
            contentElement.textContent = `${sender}: ${message}`;
            messageElement.appendChild(contentElement);
            
            const timestampElement = document.createElement('div');
            timestampElement.className = 'timestamp';
            timestampElement.textContent = getCurrentTimestamp();
            messageElement.appendChild(timestampElement);
            
            chatMessages.appendChild(messageElement);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function getCurrentTimestamp() {
            const now = new Date();
            const hours = now.getHours();
            const minutes = now.getMinutes();
            const ampm = hours >= 12 ? 'pm' : 'am';
            const formattedHours = hours % 12 || 12;
            const formattedMinutes = minutes < 10 ? '0' + minutes : minutes;
            const day = now.getDate();
            const month = now.toLocaleString('default', { month: 'short' });
            const year = now.getFullYear().toString().substr(-2);
            
            return `${formattedHours}:${formattedMinutes} ${ampm} ${day}-${month}-${year}`;
        }
    </script>
</body>
</html>
